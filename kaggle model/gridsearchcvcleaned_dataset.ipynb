{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "265eccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/nafis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/nafis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Imbalanced learning\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "412a33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../cleaned_tweets.csv')\n",
    "\n",
    "# drop rows where sentiment is 2 (news)\n",
    "df = df[df[\"sentiment\"] != 2]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a772502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30310 entries, 0 to 30309\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   message    30310 non-null  object\n",
      " 1   sentiment  30310 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 473.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9452a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot sentiment distribution\n",
    "ax = df['sentiment'].value_counts().sort_index().plot(kind='bar', color=['red', 'blue', 'green'])\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ticks=range(len(df['sentiment'].unique())), labels=df['sentiment'].unique(), rotation=0)\n",
    "\n",
    "# Annotate the bars with exact counts\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a80ec80",
   "metadata": {},
   "source": [
    "# Data Preparation for Sentiment Analysis\n",
    "\n",
    "Tweet texts will be transformed and vectorized to be fed into models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2fa266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the messages column for transformation.\n",
    "dfTweets = df[\"message\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb1cb8",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "All the tweets are first split into arrays of words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "634d9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTokenizedArray(sentences):\n",
    "    \"\"\"\n",
    "    Create lower case array of words with no punctuation.\n",
    "    :param sentences: array or series of texts\n",
    "    :return: lower case array of words with no punctuation.\n",
    "    \"\"\"\n",
    "    # Initialize tokenizer and empty array to store modified sentences.\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    tokenizedArray = []\n",
    "    for i in range(0, len(sentences)):\n",
    "        # Convert sentence to lower case.\n",
    "        sentence = sentences[i].lower()\n",
    "\n",
    "        # Split sentence into array of words with no punctuation.\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "\n",
    "        # Append word array to list.\n",
    "        tokenizedArray.append(words)\n",
    "\n",
    "    # print(tokenizedArray)\n",
    "    return tokenizedArray  # send modified contents back to calling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d205859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [tiniebeany, climate, change, is, an, interest...\n",
       "1    [watch, beforetheflood, right, here, as, leodi...\n",
       "2    [fabulous, leonardo, dicaprio, s, film, on, cl...\n",
       "3    [just, watched, this, amazing, documentary, by...\n",
       "4    [leonardo, dicaprio, s, climate, change, docum...\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizedLi = createTokenizedArray(dfTweets)\n",
    "\n",
    "pd.Series(tokenizedLi[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e6db87",
   "metadata": {},
   "source": [
    "## Stop Word Removal\n",
    "\n",
    "Stop words are the words that do not add any significant values to the query search, such as \"the\", \"a\", and \"an\". They are safe to be removed from the tokenized list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d04cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/nafis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/nafis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/nafis/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# To get stop words and wordnet for lemmatization.\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "\n",
    "\n",
    "def removeStopWords(tokenList):\n",
    "    \"\"\"\n",
    "    Create array of words with no punctuation or stop words.\n",
    "    :param tokenList: tokenized list\n",
    "    :return: array of words with no punctuation or stop words.\n",
    "    \"\"\"\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    shorterSentences = []  # Declare empty array of sentences.\n",
    "\n",
    "    for sentence in tokenList:\n",
    "        shorterSentence = []  # Declare empty array of words in single sentence.\n",
    "        for word in sentence:\n",
    "            if word not in stopWords:\n",
    "                # Remove leading and trailing spaces.\n",
    "                word = word.strip()\n",
    "\n",
    "                # Ignore single character words and digits.\n",
    "                if len(word) > 1 and word.isdigit() == False:\n",
    "                    # Add remaining words to list.\n",
    "                    shorterSentence.append(word)\n",
    "        shorterSentences.append(shorterSentence)\n",
    "    return shorterSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c59afa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence BEFORE removing stop words:\n",
      "['tiniebeany', 'climate', 'change', 'is', 'an', 'interesting', 'hustle', 'as', 'it', 'was', 'global', 'warming', 'but', 'the', 'planet', 'stopped', 'warming', 'for', '15', 'yes', 'while', 'the', 'suv', 'boom']\n",
      "\n",
      "\n",
      "Sample sentence AFTER removing stop words:\n",
      "['tiniebeany', 'climate', 'change', 'interesting', 'hustle', 'global', 'warming', 'planet', 'stopped', 'warming', 'yes', 'suv', 'boom']\n"
     ]
    }
   ],
   "source": [
    "tokenizedNoStopLi = removeStopWords(tokenizedLi)\n",
    "\n",
    "print(f\"Sample sentence BEFORE removing stop words:\\n{tokenizedLi[0]}\")\n",
    "print(f\"\\n\\nSample sentence AFTER removing stop words:\\n{tokenizedNoStopLi[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41e7401",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "English words are often time variations of a root word. Lemmatization reduces words to their base or dictionary form (lemma) by considering the context and part of speech. Unlike stemming, lemmatization produces actual words that exist in the language, which can improve the sentiment algorithm by grouping related words more accurately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ccec490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizeWords(sentenceArrays):\n",
    "    \"\"\"\n",
    "    Reduces words to their base form (lemma) and rebuilds the sentences.\n",
    "    :param sentenceArrays: sentences list\n",
    "    :return: array of sentences with lemmatized words\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatizedSentences = []\n",
    "    for sentenceArray in sentenceArrays:\n",
    "        lemmatizedArray = []  # Declare empty array of words.\n",
    "        for word in sentenceArray:\n",
    "            lemmatizedArray.append(lemmatizer.lemmatize(word))  # Add lemmatized word.\n",
    "\n",
    "        # Convert array back to sentence of lemmatized words.\n",
    "        delimeter = \" \"\n",
    "        sentence = delimeter.join(lemmatizedArray)\n",
    "\n",
    "        # Append lemmatized sentence to list of sentences.\n",
    "        lemmatizedSentences.append(sentence)\n",
    "    return lemmatizedSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5af6adea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence BEFORE lemmatization:\n",
      "['tiniebeany', 'climate', 'change', 'interesting', 'hustle', 'global', 'warming', 'planet', 'stopped', 'warming', 'yes', 'suv', 'boom']\n",
      "\n",
      "Sample sentence AFTER lemmatization:\n",
      "tiniebeany climate change interesting hustle global warming planet stopped warming yes suv boom\n"
     ]
    }
   ],
   "source": [
    "lemmatizedLi = lemmatizeWords(tokenizedNoStopLi)\n",
    "\n",
    "print(f\"Sample sentence BEFORE lemmatization:\\n{tokenizedNoStopLi[0]}\")\n",
    "print(f\"\\nSample sentence AFTER lemmatization:\\n{lemmatizedLi[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b01de91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 24248\n",
      "Test set size: 6062\n",
      "Training set sentiment distribution:\n",
      "sentiment\n",
      "-1     2999\n",
      " 0     5580\n",
      " 1    15669\n",
      "Name: count, dtype: int64\n",
      "Test set sentiment distribution:\n",
      "sentiment\n",
      "-1     750\n",
      " 0    1395\n",
      " 1    3917\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split train/test (stratified to keep class distribution)\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    lemmatizedLi,  # use lemmatized sentences\n",
    "    df['sentiment'],\n",
    "    test_size=0.2,\n",
    "    stratify=df['sentiment'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train_full)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"Training set sentiment distribution:\\n{y_train_full.value_counts().sort_index()}\")\n",
    "print(f\"Test set sentiment distribution:\\n{y_test.value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a72feb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 26548\n",
      "Sample feature names: ['rt', 'climate', 'change', 'pdf', '_niallmccarthy', 'ga14indivisible', 'rachelheldevans', 'think', 'accurate', 'many']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train_full)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "print(f\"Sample feature names: {list(vectorizer.vocabulary_.keys())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db96933b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CountVectorizer with vocabulary size: 26548\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set size: 24248\n",
      "After SMOTE-Tomek size: 46901\n",
      "Original class distribution: Counter({1: 15669, 0: 5580, -1: 2999})\n",
      "After SMOTE-Tomek distribution: Counter({-1: 15654, 0: 15624, 1: 15623})\n"
     ]
    }
   ],
   "source": [
    "# Visualize class distribution before/after SMOTE-Tomek\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Original training distribution\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(Counter(y_train_full).keys(), Counter(y_train_full).values())\n",
    "plt.title(\"Before SMOTE-Tomek\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Vectorize only the training data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train_full)\n",
    "\n",
    "# Use the CountVectorizer\n",
    "print(f\"Using CountVectorizer with vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "\n",
    "# Apply SMOTE-Tomek\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_res, y_res = smt.fit_resample(X_train_vectorized, y_train_full)\n",
    "\n",
    "# Oversampled distribution\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(Counter(y_res).keys(), Counter(y_res).values(), color='orange')\n",
    "plt.title(\"After SMOTE-Tomek\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original training set size: {len(y_train_full)}\")\n",
    "print(f\"After SMOTE-Tomek size: {len(y_res)}\")\n",
    "print(f\"Original class distribution: {Counter(y_train_full)}\")\n",
    "print(f\"After SMOTE-Tomek distribution: {Counter(y_res)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d022245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),  # Only CountVectorizer for feature extraction\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'vectorizer': [CountVectorizer()],\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "        'classifier': [LogisticRegression(max_iter=1000, random_state=42)],\n",
    "        'classifier__C': [0.1, 1, 10]\n",
    "    },\n",
    "    {\n",
    "        'vectorizer': [CountVectorizer()],\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "        'classifier': [MultinomialNB()],\n",
    "        'classifier__alpha': [0.1, 0.5, 1.0]\n",
    "    },\n",
    "    {\n",
    "        'vectorizer': [CountVectorizer()],\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "        'classifier': [RidgeClassifier(random_state=42)],\n",
    "        'classifier__alpha': [0.1, 1.0, 10.0]\n",
    "    },\n",
    "    {\n",
    "        'vectorizer': [CountVectorizer()],\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "        'classifier': [RandomForestClassifier(random_state=42)],\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "010afa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV with CountVectorizer...\n",
      "Training data size: 24248\n",
      "Fitting GridSearchCV...\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.0s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.3s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.3s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.3s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.3s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.6s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.9s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.9s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   5.1s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   5.0s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=10, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   3.3s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=10, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   3.4s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=10, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   3.3s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=10, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   3.7s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=10, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   3.7s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   7.7s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   8.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   8.5s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   9.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   9.5s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   0.9s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.5, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.5, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.5, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.5, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.5, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.5, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.5, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   0.9s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.5, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.5, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=0.5, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   0.9s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=10, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   6.6s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   0.9s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   0.9s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   0.9s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=MultinomialNB(), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   0.9s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=10, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   7.1s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=10, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   8.2s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=10, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   7.6s\n",
      "[CV] END classifier=LogisticRegression(max_iter=1000, random_state=42), classifier__C=10, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   8.1s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.1s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.0s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.9s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.0s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.1s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.8s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.7s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.6s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.5s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=10.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.4s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=10.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.4s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=1.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=10.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.4s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=10.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.4s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.6s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=0.1, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.5s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=10.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.3s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=10.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   0.9s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=10.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   0.9s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=10.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=10.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=RidgeClassifier(random_state=42), classifier__alpha=10.0, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.0s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=  21.9s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=  22.0s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=  22.4s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=  22.4s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=  22.6s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=  45.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time= 1.1min\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time= 1.1min\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=  46.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=  46.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=  46.5s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time= 1.1min\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=  46.5s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time= 1.2min\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time= 1.2min\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.7s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.4s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   0.6s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   1.5s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.2s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.3s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.2s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.3s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=10, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.2s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   1.0s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.4s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.6s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.4s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.5s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=100, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   2.4s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.0s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.0s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.2s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 1); total time=   2.0s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.2s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.0s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=20, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time=   4.1s\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time= 1.4min\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time= 1.4min\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time= 1.4min\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time= 1.4min\n",
      "[CV] END classifier=RandomForestClassifier(random_state=42), classifier__max_depth=None, classifier__n_estimators=200, vectorizer=CountVectorizer(), vectorizer__ngram_range=(1, 2); total time= 1.5min\n",
      "\n",
      "GridSearchCV completed in 178.92 seconds\n",
      "\n",
      "==================================================\n",
      "BEST MODEL RESULTS\n",
      "==================================================\n",
      "Best Model: RidgeClassifier\n",
      "Best Parameters: {'classifier': RidgeClassifier(random_state=42), 'classifier__alpha': 10.0, 'vectorizer': CountVectorizer(), 'vectorizer__ngram_range': (1, 2)}\n",
      "Best Cross-Validation Accuracy Score: 0.7441\n",
      "\n",
      "Evaluating on test set...\n",
      "Test Set Accuracy Score: 0.7433\n",
      "\n",
      "==============================\n",
      "CLASSIFICATION REPORT\n",
      "==============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.44      0.56       750\n",
      "     Neutral       0.59      0.40      0.48      1395\n",
      "    Positive       0.77      0.92      0.84      3917\n",
      "\n",
      "    accuracy                           0.74      6062\n",
      "   macro avg       0.71      0.59      0.63      6062\n",
      "weighted avg       0.73      0.74      0.72      6062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run GridSearchCV with CountVectorizer and multiple classifiers\n",
    "print(\"Starting GridSearchCV with CountVectorizer...\")\n",
    "print(f\"Training data size: {len(X_train_full)}\")\n",
    "\n",
    "# Run GridSearchCV\n",
    "start_time = time.time()\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,  # 5-fold cross-validation for faster execution\n",
    "    scoring=['accuracy', 'f1_macro'],  # optimize for accuracy and f1 score\n",
    "    refit='accuracy',  # refit using best accuracy score\n",
    "    n_jobs=-1,  # use all available cores\n",
    "    verbose=2  # show progress\n",
    ")\n",
    "\n",
    "print(\"Fitting GridSearchCV...\")\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nGridSearchCV completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Display best results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BEST MODEL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best Model: {type(grid.best_estimator_['classifier']).__name__}\")\n",
    "print(f\"Best Parameters: {grid.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy Score: {grid.best_score_:.4f}\")\n",
    "\n",
    "# Make predictions on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Test set performance\n",
    "test_accuracy = grid.score(X_test, y_test)\n",
    "print(f\"Test Set Accuracy Score: {test_accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*30)\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e1a1f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sk/y2tr30gd0rb5nh0nxms786m00000gn/T/ipykernel_38664/1549027882.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comparison_table.rename(columns={\n",
      "/var/folders/sk/y2tr30gd0rb5nh0nxms786m00000gn/T/ipykernel_38664/1549027882.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comparison_table.sort_values(by='Rank', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-Gram Range</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>C (Logistic Regression)</th>\n",
       "      <th>Alpha (Naive Bayes/Ridge)</th>\n",
       "      <th>N Estimators (Random Forest)</th>\n",
       "      <th>Max Depth (Random Forest)</th>\n",
       "      <th>Mean Test Accuracy</th>\n",
       "      <th>Mean Test F1 Score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>RidgeClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.744144</td>\n",
       "      <td>0.617990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>LogisticRegression(max_iter=1000, random_state...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.743278</td>\n",
       "      <td>0.627885</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>LogisticRegression(max_iter=1000, random_state...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.741711</td>\n",
       "      <td>0.634247</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>RidgeClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736349</td>\n",
       "      <td>0.623899</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>LogisticRegression(max_iter=1000, random_state...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.735813</td>\n",
       "      <td>0.595255</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>RidgeClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.734535</td>\n",
       "      <td>0.601703</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>LogisticRegression(max_iter=1000, random_state...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.731978</td>\n",
       "      <td>0.620819</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>LogisticRegression(max_iter=1000, random_state...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730040</td>\n",
       "      <td>0.585501</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728967</td>\n",
       "      <td>0.570301</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728637</td>\n",
       "      <td>0.599965</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.726534</td>\n",
       "      <td>0.617732</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722080</td>\n",
       "      <td>0.553458</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>RidgeClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720884</td>\n",
       "      <td>0.611849</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.718492</td>\n",
       "      <td>0.577852</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.715399</td>\n",
       "      <td>0.560124</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.715317</td>\n",
       "      <td>0.573459</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>RidgeClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714616</td>\n",
       "      <td>0.597271</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.713955</td>\n",
       "      <td>0.606260</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.558394</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>LogisticRegression(max_iter=1000, random_state...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709873</td>\n",
       "      <td>0.605169</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.704800</td>\n",
       "      <td>0.480619</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>RidgeClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.665168</td>\n",
       "      <td>0.549936</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.647682</td>\n",
       "      <td>0.267434</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.647229</td>\n",
       "      <td>0.265857</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.647064</td>\n",
       "      <td>0.266164</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.646816</td>\n",
       "      <td>0.264805</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.646198</td>\n",
       "      <td>0.261693</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.646198</td>\n",
       "      <td>0.261693</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.646198</td>\n",
       "      <td>0.261693</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>RandomForestClassifier(random_state=42)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.646198</td>\n",
       "      <td>0.261693</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   N-Gram Range                                         Classifier  \\\n",
       "0        (1, 2)                   RidgeClassifier(random_state=42)   \n",
       "1        (1, 2)  LogisticRegression(max_iter=1000, random_state...   \n",
       "2        (1, 2)  LogisticRegression(max_iter=1000, random_state...   \n",
       "3        (1, 2)                   RidgeClassifier(random_state=42)   \n",
       "4        (1, 2)  LogisticRegression(max_iter=1000, random_state...   \n",
       "5        (1, 1)                   RidgeClassifier(random_state=42)   \n",
       "6        (1, 1)  LogisticRegression(max_iter=1000, random_state...   \n",
       "7        (1, 1)  LogisticRegression(max_iter=1000, random_state...   \n",
       "8        (1, 2)                                    MultinomialNB()   \n",
       "9        (1, 1)                                    MultinomialNB()   \n",
       "10       (1, 2)                                    MultinomialNB()   \n",
       "11       (1, 1)                                    MultinomialNB()   \n",
       "12       (1, 2)                   RidgeClassifier(random_state=42)   \n",
       "13       (1, 1)            RandomForestClassifier(random_state=42)   \n",
       "14       (1, 2)            RandomForestClassifier(random_state=42)   \n",
       "15       (1, 1)            RandomForestClassifier(random_state=42)   \n",
       "16       (1, 1)                   RidgeClassifier(random_state=42)   \n",
       "17       (1, 1)                                    MultinomialNB()   \n",
       "18       (1, 2)            RandomForestClassifier(random_state=42)   \n",
       "19       (1, 1)  LogisticRegression(max_iter=1000, random_state...   \n",
       "20       (1, 2)                                    MultinomialNB()   \n",
       "21       (1, 1)                   RidgeClassifier(random_state=42)   \n",
       "22       (1, 1)            RandomForestClassifier(random_state=42)   \n",
       "23       (1, 1)            RandomForestClassifier(random_state=42)   \n",
       "24       (1, 2)            RandomForestClassifier(random_state=42)   \n",
       "25       (1, 2)            RandomForestClassifier(random_state=42)   \n",
       "26       (1, 1)            RandomForestClassifier(random_state=42)   \n",
       "27       (1, 2)            RandomForestClassifier(random_state=42)   \n",
       "28       (1, 1)            RandomForestClassifier(random_state=42)   \n",
       "29       (1, 2)            RandomForestClassifier(random_state=42)   \n",
       "\n",
       "    C (Logistic Regression)  Alpha (Naive Bayes/Ridge)  \\\n",
       "0                       NaN                       10.0   \n",
       "1                       1.0                        NaN   \n",
       "2                      10.0                        NaN   \n",
       "3                       NaN                        1.0   \n",
       "4                       0.1                        NaN   \n",
       "5                       NaN                       10.0   \n",
       "6                       1.0                        NaN   \n",
       "7                       0.1                        NaN   \n",
       "8                       NaN                        0.5   \n",
       "9                       NaN                        0.5   \n",
       "10                      NaN                        0.1   \n",
       "11                      NaN                        1.0   \n",
       "12                      NaN                        0.1   \n",
       "13                      NaN                        NaN   \n",
       "14                      NaN                        NaN   \n",
       "15                      NaN                        NaN   \n",
       "16                      NaN                        1.0   \n",
       "17                      NaN                        0.1   \n",
       "18                      NaN                        NaN   \n",
       "19                     10.0                        NaN   \n",
       "20                      NaN                        1.0   \n",
       "21                      NaN                        0.1   \n",
       "22                      NaN                        NaN   \n",
       "23                      NaN                        NaN   \n",
       "24                      NaN                        NaN   \n",
       "25                      NaN                        NaN   \n",
       "26                      NaN                        NaN   \n",
       "27                      NaN                        NaN   \n",
       "28                      NaN                        NaN   \n",
       "29                      NaN                        NaN   \n",
       "\n",
       "    N Estimators (Random Forest) Max Depth (Random Forest)  \\\n",
       "0                            NaN                       NaN   \n",
       "1                            NaN                       NaN   \n",
       "2                            NaN                       NaN   \n",
       "3                            NaN                       NaN   \n",
       "4                            NaN                       NaN   \n",
       "5                            NaN                       NaN   \n",
       "6                            NaN                       NaN   \n",
       "7                            NaN                       NaN   \n",
       "8                            NaN                       NaN   \n",
       "9                            NaN                       NaN   \n",
       "10                           NaN                       NaN   \n",
       "11                           NaN                       NaN   \n",
       "12                           NaN                       NaN   \n",
       "13                         200.0                      None   \n",
       "14                         200.0                      None   \n",
       "15                         100.0                      None   \n",
       "16                           NaN                       NaN   \n",
       "17                           NaN                       NaN   \n",
       "18                         100.0                      None   \n",
       "19                           NaN                       NaN   \n",
       "20                           NaN                       NaN   \n",
       "21                           NaN                       NaN   \n",
       "22                         100.0                        20   \n",
       "23                         200.0                        20   \n",
       "24                         100.0                        20   \n",
       "25                         200.0                        20   \n",
       "26                         100.0                        10   \n",
       "27                         100.0                        10   \n",
       "28                         200.0                        10   \n",
       "29                         200.0                        10   \n",
       "\n",
       "    Mean Test Accuracy  Mean Test F1 Score  Rank  \n",
       "0             0.744144            0.617990     1  \n",
       "1             0.743278            0.627885     2  \n",
       "2             0.741711            0.634247     3  \n",
       "3             0.736349            0.623899     4  \n",
       "4             0.735813            0.595255     5  \n",
       "5             0.734535            0.601703     6  \n",
       "6             0.731978            0.620819     7  \n",
       "7             0.730040            0.585501     8  \n",
       "8             0.728967            0.570301     9  \n",
       "9             0.728637            0.599965    10  \n",
       "10            0.726534            0.617732    11  \n",
       "11            0.722080            0.553458    12  \n",
       "12            0.720884            0.611849    13  \n",
       "13            0.718492            0.577852    14  \n",
       "14            0.715399            0.560124    15  \n",
       "15            0.715317            0.573459    16  \n",
       "16            0.714616            0.597271    17  \n",
       "17            0.713955            0.606260    18  \n",
       "18            0.713873            0.558394    19  \n",
       "19            0.709873            0.605169    20  \n",
       "20            0.704800            0.480619    21  \n",
       "21            0.665168            0.549936    22  \n",
       "22            0.647682            0.267434    23  \n",
       "23            0.647229            0.265857    24  \n",
       "24            0.647064            0.266164    25  \n",
       "25            0.646816            0.264805    26  \n",
       "26            0.646198            0.261693    27  \n",
       "27            0.646198            0.261693    27  \n",
       "28            0.646198            0.261693    27  \n",
       "29            0.646198            0.261693    27  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract results from GridSearchCV\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# Select relevant columns for comparison\n",
    "comparison_table = results[[\n",
    "    'param_vectorizer__ngram_range',\n",
    "    'param_classifier',\n",
    "    'param_classifier__C',\n",
    "    'param_classifier__alpha',\n",
    "    'param_classifier__n_estimators',\n",
    "    'param_classifier__max_depth',\n",
    "    'mean_test_accuracy',\n",
    "    'mean_test_f1_macro',\n",
    "    'rank_test_accuracy'\n",
    "]]\n",
    "\n",
    "# Rename columns for better readability\n",
    "comparison_table.rename(columns={\n",
    "    'param_vectorizer__ngram_range': 'N-Gram Range',\n",
    "    'param_classifier': 'Classifier',\n",
    "    'param_classifier__C': 'C (Logistic Regression)',\n",
    "    'param_classifier__alpha': 'Alpha (Naive Bayes/Ridge)',\n",
    "    'param_classifier__n_estimators': 'N Estimators (Random Forest)',\n",
    "    'param_classifier__max_depth': 'Max Depth (Random Forest)',\n",
    "    'mean_test_accuracy': 'Mean Test Accuracy',\n",
    "    'mean_test_f1_macro': 'Mean Test F1 Score',\n",
    "    'rank_test_accuracy': 'Rank'\n",
    "}, inplace=True)\n",
    "\n",
    "# Sort by rank\n",
    "comparison_table.sort_values(by='Rank', inplace=True)\n",
    "\n",
    "# Display the table\n",
    "comparison_table.reset_index(drop=True, inplace=True)\n",
    "comparison_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e30c2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of classifier in first row: <class 'sklearn.linear_model._ridge.RidgeClassifier'>\n",
      "First classifier object: RidgeClassifier(random_state=42)\n",
      "\n",
      "All classifiers:\n",
      "Row 0: <class 'sklearn.linear_model._ridge.RidgeClassifier'> - RidgeClassifier(random_state=42)\n",
      "Row 1: <class 'sklearn.linear_model._logistic.LogisticRegression'> - LogisticRegression(max_iter=1000, random_state=42)\n",
      "Row 2: <class 'sklearn.linear_model._logistic.LogisticRegression'> - LogisticRegression(max_iter=1000, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the structure of best_models\n",
    "best_models = comparison_table.head(3).copy()\n",
    "print(\"Type of classifier in first row:\", type(best_models.iloc[0]['Classifier']))\n",
    "print(\"First classifier object:\", best_models.iloc[0]['Classifier'])\n",
    "print(\"\\nAll classifiers:\")\n",
    "for i, classifier in enumerate(best_models['Classifier']):\n",
    "    print(f\"Row {i}: {type(classifier)} - {classifier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b56ffdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Evaluating Model: RidgeClassifier\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.44      0.56       750\n",
      "     Neutral       0.59      0.40      0.48      1395\n",
      "    Positive       0.77      0.92      0.84      3917\n",
      "\n",
      "    accuracy                           0.74      6062\n",
      "   macro avg       0.71      0.59      0.63      6062\n",
      "weighted avg       0.73      0.74      0.72      6062\n",
      "\n",
      "==================================================\n",
      "Evaluating Model: LogisticRegression\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.44      0.56       750\n",
      "     Neutral       0.59      0.40      0.48      1395\n",
      "    Positive       0.77      0.92      0.84      3917\n",
      "\n",
      "    accuracy                           0.74      6062\n",
      "   macro avg       0.71      0.59      0.63      6062\n",
      "weighted avg       0.73      0.74      0.72      6062\n",
      "\n",
      "==================================================\n",
      "Evaluating Model: LogisticRegression\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.46      0.56       750\n",
      "     Neutral       0.57      0.45      0.50      1395\n",
      "    Positive       0.79      0.90      0.84      3917\n",
      "\n",
      "    accuracy                           0.74      6062\n",
      "   macro avg       0.69      0.60      0.63      6062\n",
      "weighted avg       0.73      0.74      0.73      6062\n",
      "\n",
      "==================================================\n",
      "Evaluating Model: LogisticRegression\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.46      0.56       750\n",
      "     Neutral       0.57      0.45      0.50      1395\n",
      "    Positive       0.79      0.90      0.84      3917\n",
      "\n",
      "    accuracy                           0.74      6062\n",
      "   macro avg       0.69      0.60      0.63      6062\n",
      "weighted avg       0.73      0.74      0.73      6062\n",
      "\n",
      "==================================================\n",
      "Evaluating Model: LogisticRegression\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.70      0.48      0.57       750\n",
      "     Neutral       0.55      0.46      0.50      1395\n",
      "    Positive       0.79      0.89      0.84      3917\n",
      "\n",
      "    accuracy                           0.74      6062\n",
      "   macro avg       0.68      0.61      0.64      6062\n",
      "weighted avg       0.72      0.74      0.73      6062\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.70      0.48      0.57       750\n",
      "     Neutral       0.55      0.46      0.50      1395\n",
      "    Positive       0.79      0.89      0.84      3917\n",
      "\n",
      "    accuracy                           0.74      6062\n",
      "   macro avg       0.68      0.61      0.64      6062\n",
      "weighted avg       0.72      0.74      0.73      6062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the top 3 best models from comparison_table\n",
    "best_models = comparison_table.head(3).copy()\n",
    "\n",
    "# Iterate through each best model\n",
    "for _, row in best_models.iterrows():\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Evaluating Model: {type(row['Classifier']).__name__}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Extract the best parameters for the current model\n",
    "    pipeline.set_params(\n",
    "        vectorizer__ngram_range=row['N-Gram Range'],\n",
    "        classifier=row['Classifier']  # Use the classifier instance directly\n",
    "    )\n",
    "    \n",
    "    # Set additional parameters based on classifier type\n",
    "    if isinstance(row['Classifier'], LogisticRegression):\n",
    "        pipeline.set_params(classifier__C=row['C (Logistic Regression)'])\n",
    "    elif isinstance(row['Classifier'], MultinomialNB):\n",
    "        pipeline.set_params(classifier__alpha=row['Alpha (Naive Bayes/Ridge)'])\n",
    "    elif isinstance(row['Classifier'], RidgeClassifier):\n",
    "        pipeline.set_params(classifier__alpha=row['Alpha (Naive Bayes/Ridge)'])\n",
    "    elif isinstance(row['Classifier'], RandomForestClassifier):\n",
    "        pipeline.set_params(\n",
    "            classifier__n_estimators=int(row['N Estimators (Random Forest)']),\n",
    "            classifier__max_depth=row['Max Depth (Random Forest)']\n",
    "        )\n",
    "    \n",
    "    # Refit the pipeline with the best parameters\n",
    "    pipeline.fit(X_train_full, y_train_full)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Display the classification report\n",
    "    print(classification_report(y_test, y_pred, target_names=['Negative', 'Neutral', 'Positive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
